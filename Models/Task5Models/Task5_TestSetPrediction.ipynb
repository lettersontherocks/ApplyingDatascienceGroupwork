{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b514a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task5 testset prediction \n",
    "# The XGB regression model with the best prediction was selected for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2455ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction function\n",
    "def extract_statistical_features(df):\n",
    "    features = []\n",
    "    grouped = df.groupby(\"Case#\")\n",
    "    \n",
    "    for cid, group in grouped:\n",
    "        row = {\"Case#\": cid}\n",
    "        for p in [f\"P{i}\" for i in range(1, 8)]:\n",
    "            row[f\"{p}_mean\"] = group[p].mean()\n",
    "            row[f\"{p}_std\"] = group[p].std()\n",
    "            row[f\"{p}_min\"] = group[p].min()\n",
    "            row[f\"{p}_max\"] = group[p].max()\n",
    "        row[\"Spacecraft#\"] = group[\"Spacecraft#\"].iloc[0]\n",
    "        features.append(row)\n",
    "\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ef4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label extraction function\n",
    "def extract_labels(df):\n",
    "    case_ids = df[\"Case#\"].unique()\n",
    "    label_dict = {}\n",
    "    for cid in case_ids:\n",
    "        d = df[df[\"Case#\"] == cid].iloc[0]\n",
    "        task1 = 0 if d[\"Condition\"].lower() == \"normal\" else 1\n",
    "\n",
    "        if task1 == 0:\n",
    "            task2, task3, task4, task5 = 0, 0, 0, 100.0\n",
    "        else:\n",
    "            if d[[f\"Bubble_BP{i}\" for i in range(1, 8)] + [\"Bubble_BV1\"]].sum() > 0:\n",
    "                task2 = 2\n",
    "                task3 = np.argmax(d[[f\"Bubble_BP{i}\" for i in range(1, 8)] + [\"Bubble_BV1\"]].values) + 1\n",
    "                task4 = 0\n",
    "                task5 = 100.0\n",
    "            elif d[[f\"Opening_Ratio_SV{i}\" for i in range(1, 5)]].min() < 100:\n",
    "                task2 = 3\n",
    "                sv_values = [d[f\"Opening_Ratio_SV{i}\"] for i in range(1, 5)]\n",
    "                task4 = np.argmin(sv_values) + 1\n",
    "                task5 = float(min(sv_values))\n",
    "            else:\n",
    "                task2, task3, task4, task5 = 1, 0, 0, 100.0\n",
    "\n",
    "        label_dict[cid] = {\n",
    "            \"task1\": task1,\n",
    "            \"task2\": task2,\n",
    "            \"task3\": task3,\n",
    "            \"task4\": task4,\n",
    "            \"task5\": task5\n",
    "        }\n",
    "    return label_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c396198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is being loaded and processed...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and process training data\n",
    "print(\"Training data is being loaded and processed...\")\n",
    "df = pd.read_csv(\"merged_dataset.csv\")\n",
    "\n",
    "# Converting Yes/No to 1/0\n",
    "for col in [f\"Bubble_BP{i}\" for i in range(1, 8)] + [\"Bubble_BV1\"]:\n",
    "    df[col] = df[col].replace({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "\n",
    "# Extract labels and features\n",
    "label_dict = extract_labels(df)\n",
    "features_df = extract_statistical_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8045648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification model is being trained....\n",
      "[task 1 - XGBoost]\n",
      "accuracy: 0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.94      0.90      0.91        36\n",
      "weighted avg       0.93      0.92      0.91        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Training a classification model for Tasks 1-4\n",
    "print(\"The classification model is being trained....\")\n",
    "\n",
    "# Task 1: fault detection\n",
    "features_df[\"label\"] = [label_dict[cid][\"task1\"] for cid in features_df[\"Case#\"]]\n",
    "X = features_df.drop(columns=[\"Case#\", \"label\"])\n",
    "y = features_df[\"label\"].astype(int).values\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb1 = XGBClassifier(eval_metric=\"logloss\")\n",
    "xgb1.fit(X_train1, y_train1)\n",
    "print(\"[task 1 - XGBoost]\")\n",
    "print(\"accuracy:\", accuracy_score(y_test1, xgb1.predict(X_test1)))\n",
    "print(classification_report(y_test1, xgb1.predict(X_test1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f7f8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Raw Labeled Values: [0 2 3]\n",
      "Task 2 Encoded Tagged Values: [0 1 2]\n",
      "[Task 2 - XGBoost]\n",
      "accuracy: 0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        21\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.95      0.95        36\n",
      "weighted avg       0.94      0.94      0.94        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['task2_label_encoder.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task2: Type of fault\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "features_df[\"label\"] = [label_dict[cid][\"task2\"] for cid in features_df[\"Case#\"]]\n",
    "X = features_df.drop(columns=[\"Case#\", \"label\"])\n",
    "y = features_df[\"label\"].astype(int).values\n",
    "\n",
    "print(\"Task 2 Raw Labeled Values:\", np.unique(y))\n",
    "\n",
    "# use LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"Task 2 Encoded Tagged Values:\", np.unique(y))\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb2 = XGBClassifier(eval_metric=\"mlogloss\")\n",
    "xgb2.fit(X_train2, y_train2)\n",
    "print(\"[Task 2 - XGBoost]\")\n",
    "print(\"accuracy:\", accuracy_score(y_test2, xgb2.predict(X_test2)))\n",
    "print(classification_report(y_test2, xgb2.predict(X_test2), zero_division=0))\n",
    "\n",
    "# Save mapping relationships for use in forecasting\n",
    "joblib.dump(le, 'task2_label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64ca9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task 3 - XGBoost]\n",
      "accuracy: 0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.71      0.71      0.71        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tasl3: Bubble position\n",
    "features_df[\"label\"] = [label_dict[cid][\"task3\"] for cid in features_df[\"Case#\"]]\n",
    "X = features_df.drop(columns=[\"Case#\", \"label\"])\n",
    "y = features_df[\"label\"].astype(int).values\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "# Save mapping relationships for use in forecasting\n",
    "xgb3 = XGBClassifier(eval_metric=\"mlogloss\", num_class=9)\n",
    "xgb3.fit(X_train3, y_train3)\n",
    "print(\"[Task 3 - XGBoost]\")\n",
    "print(\"accuracy:\", accuracy_score(y_test3, xgb3.predict(X_test3)))\n",
    "print(classification_report(y_test3, xgb3.predict(X_test3), zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6794fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task 4 - XGBoost]\n",
      "accuracy: 0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        26\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      0.67      0.80         3\n",
      "           4       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.99      0.83      0.89        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task4: Faulty valves\n",
    "features_df[\"label\"] = [label_dict[cid][\"task4\"] for cid in features_df[\"Case#\"]]\n",
    "X = features_df.drop(columns=[\"Case#\", \"label\"])\n",
    "y = features_df[\"label\"].astype(int).values\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb4 = XGBClassifier(eval_metric=\"mlogloss\", num_class=5)\n",
    "xgb4.fit(X_train4, y_train4)\n",
    "print(\"[Task 4 - XGBoost]\")\n",
    "print(\"accuracy:\", accuracy_score(y_test4, xgb4.predict(X_test4)))\n",
    "print(classification_report(y_test4, xgb4.predict(X_test4), zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb803346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The regression model is being trained...\n",
      "[Task 5 - XGBoost regression model]\n",
      " (MSE): 48.3476\n",
      " (RMSE): 6.9532\n",
      " (MAE): 4.5617\n",
      " (R²): 0.9520\n",
      "[ 0. 75. 50. 75. 25. 25. 25. 25. 75. 25.  0. 25.  0. 50.  0. 75. 50. 25.\n",
      " 75. 50. 25.  0. 25. 50.  0. 75. 75. 25. 50. 50. 50. 75.  0. 75. 50. 50.\n",
      "  0. 50.]\n",
      "[75.  0. 50. 75.  0. 25.  0. 75.  0. 25.]\n",
      "[ 6.3326771e+01  1.2763156e+00  5.1074196e+01  7.5010635e+01\n",
      "  1.1311181e+00  3.1071983e+01 -1.9518977e-02  6.0595741e+01\n",
      " -1.5686054e-02  3.4939659e+01]\n"
     ]
    }
   ],
   "source": [
    "# 3. Training regression models for task 5\n",
    "print(\"\\nThe regression model is being trained...\")\n",
    "\n",
    "# Filtering out valve fault data\n",
    "features_df[\"task2\"] = [label_dict[cid][\"task2\"] for cid in features_df[\"Case#\"]]\n",
    "features_df[\"task5\"] = [label_dict[cid][\"task5\"] for cid in features_df[\"Case#\"]]\n",
    "\n",
    "# Training valve opening regression models (using only valve failure cases)\n",
    "sv_fault_df = features_df[features_df[\"task2\"] == 3].copy()\n",
    "\n",
    "if len(sv_fault_df) > 0:\n",
    "    X_sv = sv_fault_df.drop(columns=[\"Case#\", \"task2\", \"task5\", \"label\"])\n",
    "    y_sv = sv_fault_df[\"task5\"].values\n",
    "    \n",
    "    # Training-Test Set Splitting\n",
    "    X_train5, X_test5, y_train5, y_test5 = train_test_split(\n",
    "        X_sv, y_sv, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Using the XGBoost regression model\n",
    "    xgb_regressor = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4\n",
    "    )\n",
    "    \n",
    "    xgb_regressor.fit(X_train5, y_train5)\n",
    "    \n",
    "    # assessment model\n",
    "    y_pred5 = xgb_regressor.predict(X_test5)\n",
    "    \n",
    "    # Calculation of assessment indicators\n",
    "    mse = mean_squared_error(y_test5, y_pred5)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test5, y_pred5)\n",
    "    r2 = r2_score(y_test5, y_pred5)\n",
    "    \n",
    "    print(\"[Task 5 - XGBoost regression model]\")\n",
    "    print(f\" (MSE): {mse:.4f}\")\n",
    "    print(f\" (RMSE): {rmse:.4f}\")\n",
    "    print(f\" (MAE): {mae:.4f}\")\n",
    "    print(f\" (R²): {r2:.4f}\")\n",
    "    print(y_train5)\n",
    "    print(y_test5)\n",
    "    print(y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b341a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 regression models have been saved as 'xgb_valve_opening_regressor.joblib'\n"
     ]
    }
   ],
   "source": [
    "if xgb_regressor is not None:\n",
    "    joblib.dump(xgb_regressor, 'xgb_valve_opening_regressor.joblib')\n",
    "    print(\"Task 5 regression models have been saved as 'xgb_valve_opening_regressor.joblib'\")\n",
    "else:\n",
    "    print(\"There is not enough valve failure data to train the regression model型\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c19ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data being loaded and processed...\n"
     ]
    }
   ],
   "source": [
    "# 5. Reading and processing test data sets\n",
    "print(\"\\nTesting data being loaded and processed...\")\n",
    "test_df = pd.read_csv(\"merged_test_dataset.csv\")\n",
    "\n",
    "# Test data preprocessing\n",
    "for col in [f\"Bubble_BP{i}\" for i in range(1, 8)] + [\"Bubble_BV1\"]:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].replace({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "\n",
    "# Extract test set features\n",
    "features_df_test = extract_statistical_features(test_df)\n",
    "\n",
    "# Extracting the list of test set case IDs\n",
    "cid_list = features_df_test[\"Case#\"].values\n",
    "X_test = features_df_test.drop(columns=[\"Case#\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459b9b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total predicted 46 test cases\n",
      "\n",
      "Preview of the test set prediction results:\n",
      "    Case#  Task1  Task2  Task3  Task4       Task5\n",
      "0     178      1      1      2      0  100.000000\n",
      "1     179      1      2      0      2   25.016947\n",
      "2     180      0      0      0      0  100.000000\n",
      "3     181      0      0      0      0  100.000000\n",
      "4     182      0      0      0      0  100.000000\n",
      "5     183      0      0      0      0  100.000000\n",
      "6     184      1      2      0      1    4.428387\n",
      "7     185      0      0      0      0  100.000000\n",
      "8     186      1      1      6      0  100.000000\n",
      "9     187      0      0      0      0  100.000000\n",
      "10    188      1      1      3      0  100.000000\n",
      "11    189      0      0      0      0  100.000000\n",
      "12    190      1      2      0      3   50.733398\n",
      "13    191      0      0      0      0  100.000000\n",
      "14    192      1      2      0      1    4.502021\n",
      "15    193      1      1      1      0  100.000000\n",
      "16    194      0      0      0      0  100.000000\n",
      "17    195      0      0      0      0  100.000000\n",
      "18    196      1      1      4      0  100.000000\n",
      "19    197      1      1      7      0  100.000000\n",
      "20    198      0      0      0      0  100.000000\n",
      "21    199      0      0      0      0  100.000000\n",
      "22    200      1      2      0      1    4.428387\n",
      "23    201      0      0      0      0  100.000000\n",
      "24    202      1      2      0      3   63.185085\n",
      "25    203      0      0      0      0  100.000000\n",
      "26    204      1      1      3      0  100.000000\n",
      "27    205      1      2      0      2   69.202965\n",
      "28    206      0      0      0      0  100.000000\n",
      "29    207      1      2      0      1    4.401771\n",
      "30    208      0      0      0      0  100.000000\n",
      "31    209      1      1      7      0  100.000000\n",
      "32    210      0      0      0      0  100.000000\n",
      "33    211      0      0      0      0  100.000000\n",
      "34    212      1      2      0      2   73.598099\n",
      "35    213      0      0      0      0  100.000000\n",
      "36    214      1      2      0      4   30.433552\n",
      "37    215      0      0      0      0  100.000000\n",
      "38    216      1      1      1      0  100.000000\n",
      "39    217      0      0      0      0  100.000000\n",
      "40    218      1      2      0      1    4.356144\n",
      "41    219      1      1      5      0  100.000000\n",
      "42    220      0      0      0      0  100.000000\n",
      "43    221      1      1      2      0  100.000000\n",
      "44    222      1      2      0      1    4.401771\n",
      "45    223      0      0      0      0  100.000000\n",
      "All predictions have been saved to  'xgb_complete_test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# 6. Prediction on the test set\n",
    "\n",
    "# Pre-existing predictions for tasks 1-4\n",
    "pred_task1 = xgb1.predict(X_test)\n",
    "pred_task2 = xgb2.predict(X_test)\n",
    "pred_task3 = xgb3.predict(X_test)\n",
    "pred_task4 = xgb4.predict(X_test)\n",
    "\n",
    "# Preparing a list for storing the final prediction results\n",
    "results = []\n",
    "\n",
    "# Predictions for each test case\n",
    "for i, cid in enumerate(cid_list):\n",
    "    if i >= len(pred_task1):  # Ensure that the index does not exceed the size of the predicted result\n",
    "        print(f\"Warning: index {i} is out of range {len(pred_task1)}\")\n",
    "        break\n",
    "        \n",
    "    t1 = int(pred_task1[i])\n",
    "    t2 = int(pred_task2[i])\n",
    "    t3 = int(pred_task3[i])\n",
    "    t4 = int(pred_task4[i])\n",
    "    t5 = 100.0  \n",
    "    \n",
    "    # Adjustment of forecasts based on logical relationships between tasks\n",
    "    if t1 == 0:  # normal condition\n",
    "        t2, t3, t4, t5 = 0, 0, 0, 100.0\n",
    "    else:  # abnormal state\n",
    "        if t2 == 1:  # malfunction of air bubble\n",
    "            # Keep the bubble position predicted and valve related set to normal\n",
    "            t4 = 0\n",
    "            t5 = 100.0\n",
    "        elif t2 == 2:  # Valve Failure\n",
    "            t3 = 0\n",
    "            try:\n",
    "                valve_features = X_test.iloc[i:i+1]\n",
    "                t5 = float(xgb_regressor.predict(valve_features)[0])\n",
    "                t5 = max(0.0, min(t5, 99.9))  \n",
    "            except Exception as e:\n",
    "                print(f\"Case {cid} Valve Opening Prediction Failed: {str(e)}，Use default values\")\n",
    "                t5 = 50.0  # If the prediction fails, use the default value\n",
    "    \n",
    "        else: # Other faults\n",
    "            t3 = 0\n",
    "            t4 = 0\n",
    "            t5 = 100.0\n",
    "            # Predicting Valve Openings Using the Regression Model from Task 5\n",
    "\n",
    "    # Fixed: add predictions to results list on every loop\n",
    "    results.append({\n",
    "        \"Case#\": cid,\n",
    "        \"Task1\": t1,\n",
    "        \"Task2\": t2,\n",
    "        \"Task3\": t3,\n",
    "        \"Task4\": t4,\n",
    "        \"Task5\": t5\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# 7. Display and save forecast results\n",
    "print(f\"\\nTotal predicted {len(result_df)} test cases\")\n",
    "print(\"\\nPreview of the test set prediction results:\")\n",
    "print(result_df.head(46)) \n",
    "\n",
    "# Save forecast results\n",
    "result_df.to_csv(\"xgb_complete_test_predictions.csv\", index=False)\n",
    "print(\"All predictions have been saved to  'xgb_complete_test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9302dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics on projected results:\n",
      "Total cases: 46\n",
      "Normal cases (Task1=0): 23\n",
      "Abnormal Cases (Task1=1): 23\n",
      "where the air bubble malfunctions (Task2=2): 11\n",
      "where the valve fails (Task2=3): 12\n"
     ]
    }
   ],
   "source": [
    "# 8. Analysis of projected results\n",
    "print(\"\\nStatistics on projected results:\")\n",
    "print(f\"Total cases: {len(result_df)}\")\n",
    "print(f\"Normal cases (Task1=0): {sum(result_df['Task1'] == 0)}\")\n",
    "print(f\"Abnormal Cases (Task1=1): {sum(result_df['Task1'] == 1)}\")\n",
    "print(f\"where the air bubble malfunctions (Task2=2): {sum(result_df['Task2'] == 1)}\")\n",
    "print(f\"where the valve fails (Task2=3): {sum(result_df['Task2'] == 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28999c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valve Failure Openings Prediction Analysis:\n",
      "Number of valve failure cases: 12\n",
      "Average predicted opening: 28.22%\n",
      "Minimum predicted opening: 4.36%\n",
      "Maximum predicted opening: 73.60%\n",
      "valves 1: 6cases\n",
      "valves 2: 3cases\n",
      "valves 3: 2cases\n",
      "valves 4: 1cases\n",
      "\n",
      "Forecasting and analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Openness analysis for valve failure cases\n",
    "valve_fault_cases = result_df[result_df['Task2'] == 2]\n",
    "if len(valve_fault_cases) > 0:\n",
    "    print(\"\\nValve Failure Openings Prediction Analysis:\")\n",
    "    print(f\"Number of valve failure cases: {len(valve_fault_cases)}\")\n",
    "    print(f\"Average predicted opening: {valve_fault_cases['Task5'].mean():.2f}%\")\n",
    "    print(f\"Minimum predicted opening: {valve_fault_cases['Task5'].min():.2f}%\")\n",
    "    print(f\"Maximum predicted opening: {valve_fault_cases['Task5'].max():.2f}%\")\n",
    "    \n",
    "    # Distribution statistics by valve\n",
    "    valve_counts = valve_fault_cases['Task4'].value_counts()\n",
    "    for valve_id in range(1, 5):\n",
    "        print(f\"valves {valve_id}: {valve_counts.get(valve_id, 0)}cases\")\n",
    "else:\n",
    "    print(\"\\nValve failure cases not detected in test set\")\n",
    "\n",
    "print(\"\\nForecasting and analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
